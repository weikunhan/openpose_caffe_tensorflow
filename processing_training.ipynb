{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vgg19 weights...\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 17s 0us/step\n",
      "Loaded VGG19 layer: block1_conv1\n",
      "Loaded VGG19 layer: block1_conv2\n",
      "Loaded VGG19 layer: block2_conv1\n",
      "Loaded VGG19 layer: block2_conv2\n",
      "Loaded VGG19 layer: block3_conv1\n",
      "Loaded VGG19 layer: block3_conv2\n",
      "Loaded VGG19 layer: block3_conv3\n",
      "Loaded VGG19 layer: block3_conv4\n",
      "Loaded VGG19 layer: block4_conv1\n",
      "Loaded VGG19 layer: block4_conv2\n",
      "Epoch 1/200000\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\" .....................\n",
    "\n",
    "################################################################################\n",
    "# Author: Weikun Han <weikunhan@gmail.com>\n",
    "# Crate Date: 04/07/2018        \n",
    "# Update:\n",
    "# Reference: \n",
    "#    https://github.com/michalfaber/keras_Realtime_Multi-Person_Pose_Estimation\n",
    "################################################################################\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas\n",
    "import re\n",
    "import math\n",
    "sys.path.append(\"..\")\n",
    "from model import get_training_model\n",
    "from ds_iterator import DataIterator\n",
    "from ds_generator_client import DataGeneratorClient\n",
    "from optimizers import MultiSGD\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, CSVLogger, TensorBoard\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.applications.vgg19 import VGG19\n",
    "import keras.backend as K\n",
    "\n",
    "batch_size = 10\n",
    "base_lr = 4e-5 # 2e-5\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "lr_policy =  \"step\"\n",
    "gamma = 0.333\n",
    "stepsize = 136106 #68053   // after each stepsize iterations update learning rate: lr=lr*gamma\n",
    "max_iter = 200000 # 600000\n",
    "\n",
    "# True = start data generator client, False = use augmented dataset file (deprecated)\n",
    "use_client_gen = True\n",
    "\n",
    "WEIGHTS_BEST = \"weights.best.h5\"\n",
    "TRAINING_LOG = \"training.csv\"\n",
    "LOGS_DIR = \"./logs\"\n",
    "\n",
    "def get_last_epoch():\n",
    "    data = pandas.read_csv(TRAINING_LOG)\n",
    "    return max(data['epoch'].values)\n",
    "\n",
    "\n",
    "model = get_training_model(weight_decay)\n",
    "\n",
    "from_vgg = dict()\n",
    "from_vgg['conv1_1'] = 'block1_conv1'\n",
    "from_vgg['conv1_2'] = 'block1_conv2'\n",
    "from_vgg['conv2_1'] = 'block2_conv1'\n",
    "from_vgg['conv2_2'] = 'block2_conv2'\n",
    "from_vgg['conv3_1'] = 'block3_conv1'\n",
    "from_vgg['conv3_2'] = 'block3_conv2'\n",
    "from_vgg['conv3_3'] = 'block3_conv3'\n",
    "from_vgg['conv3_4'] = 'block3_conv4'\n",
    "from_vgg['conv4_1'] = 'block4_conv1'\n",
    "from_vgg['conv4_2'] = 'block4_conv2'\n",
    "\n",
    "# load previous weights or vgg19 if this is the first run\n",
    "if os.path.exists(WEIGHTS_BEST):\n",
    "    print(\"Loading the best weights...\")\n",
    "\n",
    "    model.load_weights(WEIGHTS_BEST)\n",
    "    last_epoch = get_last_epoch() + 1\n",
    "else:\n",
    "    print(\"Loading vgg19 weights...\")\n",
    "\n",
    "    vgg_model = VGG19(include_top=False, weights='imagenet')\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if layer.name in from_vgg:\n",
    "            vgg_layer_name = from_vgg[layer.name]\n",
    "            layer.set_weights(vgg_model.get_layer(vgg_layer_name).get_weights())\n",
    "            print(\"Loaded VGG19 layer: \" + vgg_layer_name)\n",
    "\n",
    "    last_epoch = 0\n",
    "\n",
    "# prepare generators\n",
    "\n",
    "if use_client_gen:\n",
    "    train_client = DataGeneratorClient(port=5555, host=\"localhost\", hwm=160, batch_size=10)\n",
    "    train_client.start()\n",
    "    train_di = train_client.gen()\n",
    "    train_samples = 52597\n",
    "\n",
    "    val_client = DataGeneratorClient(port=5556, host=\"localhost\", hwm=160, batch_size=10)\n",
    "    val_client.start()\n",
    "    val_di = val_client.gen()\n",
    "    val_samples = 2645\n",
    "else:\n",
    "    train_di = DataIterator(\"../dataset/train_dataset.h5\", data_shape=(3, 368, 368),\n",
    "                      mask_shape=(1, 46, 46),\n",
    "                      label_shape=(57, 46, 46),\n",
    "                      vec_num=38, heat_num=19, batch_size=batch_size, shuffle=True)\n",
    "    train_samples=train_di.N\n",
    "    val_di = DataIterator(\"../dataset/val_dataset.h5\", data_shape=(3, 368, 368),\n",
    "                      mask_shape=(1, 46, 46),\n",
    "                      label_shape=(57, 46, 46),\n",
    "                      vec_num=38, heat_num=19, batch_size=batch_size, shuffle=True)\n",
    "    val_samples=val_di.N\n",
    "\n",
    "# setup lr multipliers for conv layers\n",
    "lr_mult=dict()\n",
    "for layer in model.layers:\n",
    "\n",
    "    if isinstance(layer, Conv2D):\n",
    "\n",
    "        # stage = 1\n",
    "        if re.match(\"Mconv\\d_stage1.*\", layer.name):\n",
    "            kernel_name = layer.weights[0].name\n",
    "            bias_name = layer.weights[1].name\n",
    "            lr_mult[kernel_name] = 1\n",
    "            lr_mult[bias_name] = 2\n",
    "\n",
    "        # stage > 1\n",
    "        elif re.match(\"Mconv\\d_stage.*\", layer.name):\n",
    "            kernel_name = layer.weights[0].name\n",
    "            bias_name = layer.weights[1].name\n",
    "            lr_mult[kernel_name] = 4\n",
    "            lr_mult[bias_name] = 8\n",
    "\n",
    "        # vgg\n",
    "        else:\n",
    "           kernel_name = layer.weights[0].name\n",
    "           bias_name = layer.weights[1].name\n",
    "           lr_mult[kernel_name] = 1\n",
    "           lr_mult[bias_name] = 2\n",
    "\n",
    "# configure loss functions\n",
    "\n",
    "# euclidean loss as implemented in caffe https://github.com/BVLC/caffe/blob/master/src/caffe/layers/euclidean_loss_layer.cpp\n",
    "def eucl_loss(x, y):\n",
    "    return K.sum(K.square(x - y)) / batch_size / 2\n",
    "\n",
    "losses = {}\n",
    "losses[\"weight_stage1_L1\"] = eucl_loss\n",
    "losses[\"weight_stage1_L2\"] = eucl_loss\n",
    "losses[\"weight_stage2_L1\"] = eucl_loss\n",
    "losses[\"weight_stage2_L2\"] = eucl_loss\n",
    "losses[\"weight_stage3_L1\"] = eucl_loss\n",
    "losses[\"weight_stage3_L2\"] = eucl_loss\n",
    "losses[\"weight_stage4_L1\"] = eucl_loss\n",
    "losses[\"weight_stage4_L2\"] = eucl_loss\n",
    "losses[\"weight_stage5_L1\"] = eucl_loss\n",
    "losses[\"weight_stage5_L2\"] = eucl_loss\n",
    "losses[\"weight_stage6_L1\"] = eucl_loss\n",
    "losses[\"weight_stage6_L2\"] = eucl_loss\n",
    "\n",
    "# learning rate schedule - equivalent of caffe lr_policy =  \"step\"\n",
    "iterations_per_epoch = train_samples // batch_size\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = base_lr\n",
    "    steps = epoch * iterations_per_epoch\n",
    "\n",
    "    lrate = initial_lrate * math.pow(gamma, math.floor(steps/stepsize))\n",
    "\n",
    "    return lrate\n",
    "\n",
    "# configure callbacks\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "checkpoint = ModelCheckpoint(WEIGHTS_BEST, monitor='loss', verbose=0, save_best_only=False, save_weights_only=True, mode='min', period=1)\n",
    "csv_logger = CSVLogger(TRAINING_LOG, append=True)\n",
    "tb = TensorBoard(log_dir=LOGS_DIR, histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "callbacks_list = [lrate, checkpoint, csv_logger, tb]\n",
    "\n",
    "# sgd optimizer with lr multipliers\n",
    "multisgd = MultiSGD(lr=base_lr, momentum=momentum, decay=0.0, nesterov=False, lr_mult=lr_mult)\n",
    "\n",
    "# start training\n",
    "model.compile(loss=losses, optimizer=multisgd, metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit_generator(train_di,\n",
    "                    steps_per_epoch=train_samples // batch_size,\n",
    "                    epochs=max_iter,\n",
    "                    callbacks=callbacks_list,\n",
    "                    #validation_data=val_di,\n",
    "                    #validation_steps=val_samples // batch_size,\n",
    "                    use_multiprocessing=False,\n",
    "                    initial_epoch=last_epoch\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
